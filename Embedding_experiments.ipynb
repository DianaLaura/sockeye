{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mxnet as mx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                     |Positional Embbeddings         |     | Frame Embeddings                              |\n",
    "|---------------------|-------------------------------|-----|-----------------------------------------------|\n",
    "|Positioning          | Index of word                 |     |Timestamp assigned to word                     |\n",
    "|Input Representation |[w_1, w_2]                     |     |[[w_1,T_1],[w2,T_2],[<sep>,<sep>],[[w_3,T_3]]  | \n",
    "|Stepsize between pos |constant                       |     |variabel                                       |\n",
    "|Tokens per pos       | 1                             |     | 1-2                                           |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already implemented class for positional embeddings (layers.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positional_embeddings(length, depth) -> np.ndarray:\n",
    "   \n",
    "    # (1, depth)\n",
    "    channels = np.arange(depth // 2).reshape((1, -1))\n",
    "\n",
    "    # (length, 1)\n",
    "    positions = np.arange(0, length).reshape((-1, 1))\n",
    "    scaled_positions = positions / np.power(10000, (2 * channels) / depth)\n",
    "    # sinusoids:\n",
    "    sin = np.sin(scaled_positions)\n",
    "    # cosines:\n",
    "    cos = np.cos(scaled_positions)\n",
    "    # interleave: (length, num_embed)\n",
    "    encodings = np.hstack([sin, cos])\n",
    "    return encodings\n",
    "\n",
    "class PositionalEmbeddings(mx.gluon.HybridBlock):\n",
    "    \"\"\"\n",
    "    Takes an encoded sequence and adds sinusoidal or learned positional embeddings as in Vaswani et al, 2017 to it.\n",
    "\n",
    "    :param weight_type: type of embeddings, fixed or learned.\n",
    "    :param num_embed: Embedding size.\n",
    "    :param max_seq_len: Maximum sequence length.\n",
    "    :param prefix: Name prefix for symbols of this encoder.\n",
    "    :param scale_up_input: If True, scales input data up by num_embed ** 0.5.\n",
    "    :param scale_down_positions: If True, scales positional embeddings down by num_embed ** -0.5.\n",
    "    :param weight_init: Optional initializer for learned embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 weight_type: \"C.FIXED_POSITIONAL_EMBEDDING\",\n",
    "                 num_embed: 100,\n",
    "                 max_seq_len: 100,\n",
    "                 prefix: \"pos\",\n",
    "                 scale_up_input: False,\n",
    "                 scale_down_positions: True) -> None:\n",
    "        \n",
    "        self.weight_type = weight_type\n",
    "        self.num_embed = num_embed\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.scale_up_input = scale_up_input\n",
    "        self.scale_down_positions = scale_down_positions\n",
    "        with self.name_scope():\n",
    "            if self.weight_type == \"C.FIXED_POSITIONAL_EMBEDDING\" or \"C.FRAME_EMBEDDING_SOURCE\":\n",
    "                pos_weight = get_positional_embeddings(length=self.max_seq_len, depth=self.num_embed)\n",
    "                if self.scale_down_positions:\n",
    "                    pos_weight *= self.num_embed ** -0.5\n",
    "                self.weight = self.params.get_constant('weight', pos_weight)\n",
    "            elif self.weight_type == \"C.LEARNED_POSITIONAL_EMBEDDING\":\n",
    "                self.weight = self.params.get('weight', shape=(self.max_seq_len, self.num_embed), init=weight_init)\n",
    "            else:\n",
    "                raise ValueError(\"weight_type '%s' is not supported!\" % self.weight_type)\n",
    "\n",
    "    def hybrid_forward(self, F, data, steps, weight):  # pylint: disable=arguments-differ\n",
    "        \"\"\"\n",
    "        Applies positional embeddings to input data.\n",
    "\n",
    "        :param data: Input data. Shape: (batch, length or 1, num_embed)\n",
    "        :param steps: Optional steps input. If given, shape is (batch_size or 1, seq_len,)\n",
    "        :param weight: Positional embedding constant.\n",
    "        :return: Data with positional embeddings added\n",
    "        \"\"\"\n",
    "        # (length, num_embed)\n",
    "        if steps is None:\n",
    "            # (batch, length, num_embed)\n",
    "            pos_embedding = F.slice_like(F.expand_dims(weight, axis=0), data, axes=(1,))\n",
    "        else:\n",
    "            # (batch_size or 1, seq_len, num_embed)\n",
    "            pos_embedding = F.Embedding(steps, weight, self.max_seq_len, self.num_embed)\n",
    "\n",
    "        if self.weight_type == C.FIXED_POSITIONAL_EMBEDDING:\n",
    "            pos_embedding = F.BlockGrad(pos_embedding)\n",
    "\n",
    "        if self.scale_up_input:\n",
    "            data = data * (self.num_embed ** 0.5)\n",
    "\n",
    "        return F.broadcast_add(data, pos_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class for frame embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FrameEmbeddings(mx.gluon.HybridBlock):\n",
    "    \"\"\"\n",
    "    Takes an encoded sequence with timestamps, and adds sinusoidal encoded embeddings similar to Vaswani et al. 2017, \n",
    "    but uses the timestamp instead of the position.\n",
    "\n",
    "    :param weight_type: type of embeddings, fixed or learned.\n",
    "    :param num_embed: Embedding size.\n",
    "    :param max_seq_len: Maximum sequence length.\n",
    "    :param prefix: Name prefix for symbols of this encoder.\n",
    "    :param scale_up_input: If True, scales input data up by num_embed ** 0.5.\n",
    "    :param scale_down_positions: If True, scales positional embeddings down by num_embed ** -0.5.\n",
    "    :param weight_init: Optional initializer for learned embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 weight_type: \"C.FRAME_EMBEDDING_SOURCE\",\n",
    "                 num_embed: 100,\n",
    "                 max_seq_len: 100,\n",
    "                 prefix: \"sth\",\n",
    "                 scale_up_input: False,\n",
    "                 scale_down_positions: True) -> None:\n",
    "\n",
    "        super().__init__(prefix=prefix)\n",
    "        self.weight_type = weight_type\n",
    "        self.num_embed = num_embed\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.scale_up_input = scale_up_input\n",
    "        self.scale_down_positions = scale_down_positions\n",
    "\n",
    "        with self.name_scope():\n",
    "            pos_weight = get_frame_embeddings(length=self.max_seq_len, depth=self.num_embed)\n",
    "            if self.scale_down_positions:\n",
    "                pos_weight *= self.num_embed ** -0.5\n",
    "            self.weight = self.params.get_constant('weight', pos_weight)\n",
    "           \n",
    "            \n",
    "    def hybrid_forward(self, F, data, steps, weight):  # pylint: disable=arguments-differ\n",
    "        \"\"\"\n",
    "        Applies frame embeddings to input data.\n",
    "\n",
    "        :param data: Input data. Shape: (batch, length or 1, num_embed)\n",
    "        :param steps: Optional steps input. If given, shape is (batch_size or 1, seq_len,)\n",
    "        :param weight: Positional embedding constant.\n",
    "        :return: Data with positional embeddings added\n",
    "        \"\"\"\n",
    "\n",
    "        # (length, num_embed)\n",
    "        if steps is None:\n",
    "            # (batch, length, num_embed)\n",
    "            frame_embedding = F.slice_like(F.expand_dims(weight, axis=0), data, axes=(1,))\n",
    "\n",
    "        else:\n",
    "            # (batch_size or 1, seq_len, num_embed)\n",
    "            tokens, frames = F.split(data, num_outputs = 2, axis = 2)\n",
    "\n",
    "            frames = frames.squeeze(axis=2)\n",
    "            frames = frames.squeeze(axis=2)\n",
    "            tokens = tokens.squeeze(axis=2)\n",
    "            tokens = tokens.squeeze(axis=2)\n",
    "         \n",
    "            new_weights = weight.take(frames)\n",
    "   \n",
    "            new_weights = new_weights.reshape(shape=(-3, 0))\n",
    "\n",
    "            #Padding the new weights array such that its shape is (self.config.vocab_size, self.config.num_embed)\n",
    "\n",
    "            padding = F.zeros((self.max_seq_len, self.num_embed))\n",
    "\n",
    "            padded_weights = F.concat(new_weights, padding, dim=0)\n",
    "\n",
    "            padded_weights = F.slice(padded_weights, begin=(0,0), end=(self.max_seq_len, self.num_embed))\n",
    "\n",
    "         \n",
    "            frame_embedding = F.Embedding(steps, padded_weights, self.max_seq_len, self.num_embed)\n",
    "\n",
    "        \n",
    "        frame_embedding = F.BlockGrad(frame_embedding)\n",
    "\n",
    "        if self.scale_up_input:\n",
    "            data = data * (self.num_embed ** 0.5)\n",
    "\n",
    "        return F.broadcast_add(data, frame_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 512\n",
    "length = 96\n",
    "\n",
    "Data = [\"Hello\",\"World\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data refers to the data, and F is a symbolic representation of the block, and can be more or less ignored.\n",
    "\n",
    "The get_embeddings function calculates weights for each position. For time frames, the same frame should have the same weight. So I'll initialize one array with continuous weights, and then double it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_embeddings(length, depth) -> np.ndarray:\n",
    "    \n",
    "    # (1, depth)\n",
    "    channels = np.arange(depth // 2).reshape((1, -1))\n",
    "\n",
    "    # (length, 1)\n",
    "    positions = np.arange(0, length).reshape((-1, 1))\n",
    "    scaled_positions = positions / np.power(10000, (2 * channels) / depth)\n",
    "    # sinusoids:\n",
    "    sin = np.sin(scaled_positions)\n",
    "    # cosines:\n",
    "    cos = np.cos(scaled_positions)\n",
    "    # interleave: (length, num_embed)\n",
    "    encodings = np.hstack([sin, cos])\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings_frames = get_frame_embeddings(length, depth)\n",
    "encodings_pos = get_positional_embeddings(length, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(encodings_pos.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(encodings_frames.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_frames = [[\"Hello\",0],[\"World\",2],[\"<sep>\",\"<sep>\"],[\"Buongiorno\",0],[\"Hi\",1]]\n",
    "\n",
    "#While preprocessing, the words are replaced by numbers, so...\n",
    "\n",
    "Data = mx.nd.array([[[5,0],[6,2],[4,4],[10,0],[11,1]], [[7,0],[7,1],[6,3],[4,4],[11,0]]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5, 2)\n"
     ]
    }
   ],
   "source": [
    "print(Data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The array with the source sentences needs to be reshaped such that it is still as long as the array with the target sentences, and that the last dimension has length 1. This way, the array can be read by the parallel sample iter.\n",
    "\n",
    "This means that the source array has one dimension more than the target array (4 vs. 3), but this does only need minor changes, whereas the shape (x,y,2) seems to cause major problems with mxnet itself (got errors like \"can't broadcast array\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[[[ 5.]\n",
      "   [ 0.]]\n",
      "\n",
      "  [[ 6.]\n",
      "   [ 2.]]\n",
      "\n",
      "  [[ 4.]\n",
      "   [ 4.]]\n",
      "\n",
      "  [[10.]\n",
      "   [ 0.]]\n",
      "\n",
      "  [[11.]\n",
      "   [ 1.]]]\n",
      "\n",
      "\n",
      " [[[ 7.]\n",
      "   [ 0.]]\n",
      "\n",
      "  [[ 7.]\n",
      "   [ 1.]]\n",
      "\n",
      "  [[ 6.]\n",
      "   [ 3.]]\n",
      "\n",
      "  [[ 4.]\n",
      "   [ 4.]]\n",
      "\n",
      "  [[11.]\n",
      "   [ 0.]]]]\n",
      "<NDArray 2x5x2x1 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "Data = Data.reshape(2,5,2,1)\n",
    "print(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(Data.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code snippet for data_io.py: create_batch_from_sample. Makes sure that the slicing corresponds to the increased number of dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[[ 5.  0.]\n",
      "  [ 6.  2.]\n",
      "  [ 4.  4.]\n",
      "  [10.  0.]\n",
      "  [11.  1.]]\n",
      "\n",
      " [[ 7.  0.]\n",
      "  [ 7.  1.]\n",
      "  [ 6.  3.]\n",
      "  [ 4.  4.]\n",
      "  [11.  0.]]]\n",
      "<NDArray 2x5x2 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "source_words = mx.nd.slice(Data, begin=(None, None, 0), end=(None, None, 2)).squeeze(axis=3, inplace=True)\n",
    "print(source_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[[ 5.]\n",
      "  [ 6.]\n",
      "  [ 4.]\n",
      "  [10.]\n",
      "  [11.]]\n",
      "\n",
      " [[ 7.]\n",
      "  [ 7.]\n",
      "  [ 6.]\n",
      "  [ 4.]\n",
      "  [11.]]]\n",
      "<NDArray 2x5x1 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "source_tokens = mx.nd.slice(Data, begin=(None, None, 0), end=(None, None, 1)).squeeze(axis=3, inplace=True)\n",
    "print(source_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5. 5.]\n",
      "<NDArray 2 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "source_length = mx.nd.sum((source_tokens != 0), axis=1).squeeze(axis=1, inplace=True)\n",
    "print(source_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 5\n"
     ]
    }
   ],
   "source": [
    "source_shape = Data.shape\n",
    "samples = source_shape[0]\n",
    "tokens = source_shape[1]\n",
    "\n",
    "print(samples, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding process is actually done by mxnet.symbol.embedding. The code behind works as shown below (source: https://mxnet.apache.org/versions/1.7.0/api/python/docs/api/symbol/symbol.html):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 4\n",
    "output_dim = 5\n",
    "\n",
    "#Each row in weight matrix y represents a word. So, y = (w0,w1,w2,w3)\n",
    "y = [[  0.,   1.,   2.,   3.,   4.],\n",
    "     [  5.,   6.,   7.,   8.,   9.],\n",
    "     [ 10.,  11.,  12.,  13.,  14.],\n",
    "     [ 15.,  16.,  17.,  18.,  19.]]\n",
    "\n",
    "#Input array x represents n-grams(2-gram). So, x = [(w1,w3), (w0,w2)]\n",
    "x = [[ 1.,  3.],\n",
    "     [ 0.,  2.]]\n",
    "\n",
    "#Mapped input x to its vector representation y.\n",
    "#Embedding(x, y, 4, 5)\n",
    "Embedding = [[[  5.,   6.,   7.,   8.,   9.],\n",
    "            [ 15.,  16.,  17.,  18.,  19.]],\n",
    "            [[  0.,   1.,   2.,   3.,   4.],\n",
    "            [ 10.,  11.,  12.,  13.,  14.]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          1.        ]\n",
      " [ 0.84147098  0.54030231]\n",
      " [ 0.90929743 -0.41614684]\n",
      " [ 0.14112001 -0.9899925 ]\n",
      " [-0.7568025  -0.65364362]\n",
      " [-0.95892427  0.28366219]\n",
      " [-0.2794155   0.96017029]\n",
      " [ 0.6569866   0.75390225]\n",
      " [ 0.98935825 -0.14550003]\n",
      " [ 0.41211849 -0.91113026]]\n"
     ]
    }
   ],
   "source": [
    "weights = get_frame_embeddings(10, 2)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to deliver only the weights for which a token is available. This should work, because the position is already encoded with either sine or cosine function. This way, the algorithm will also be able to see which words usually occur close together.\n",
    "\n",
    "Another goal is to separate mouthings and signs from each other, so the two arrays can be summed or concatenated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[[ 0.          1.        ]\n",
      "  [ 0.9092974  -0.41614684]\n",
      "  [-0.7568025  -0.6536436 ]\n",
      "  [ 0.          1.        ]\n",
      "  [ 0.84147096  0.5403023 ]]\n",
      "\n",
      " [[ 0.          1.        ]\n",
      "  [ 0.84147096  0.5403023 ]\n",
      "  [ 0.14112    -0.9899925 ]\n",
      "  [-0.7568025  -0.6536436 ]\n",
      "  [ 0.          1.        ]]]\n",
      "<NDArray 2x5x2 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "maxlen = 10\n",
    "\n",
    "tokens, frames = Data.split(num_outputs=2, axis = 2)\n",
    "\n",
    "\n",
    "weights = mx.nd.array(weights)\n",
    "\n",
    "tokens = tokens.squeeze(axis = 2)\n",
    "tokens = tokens.squeeze(axis = 2)\n",
    "\n",
    "frames = frames.squeeze(axis = 2)\n",
    "frames = frames.squeeze(axis = 2)\n",
    "\n",
    "new_weights = weights.take(frames)\n",
    "print(new_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(new_weights.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(weights.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5)\n"
     ]
    }
   ],
   "source": [
    "print(tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "print(Data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the embedding layer (which I can't really test here), the shape of new_weights must be (input_dim, output_dim). The output dim is easy to find, since it corresponds to the number of positions / embeddings calculated. The input dim in sockeye is currently the size of the vocab, but that doesn't work in this case. Doubling the weight matrix does only work in this example, but it is very unlikely that this is a reliable solution for sockeye. Another problem is that sockeye works with symbolic programming at this point, which means that it is nearly impossible to print out the dimensions of any matrices.\n",
    "\n",
    "The goal is to find a number for the input dim that can be constructed in a logical, reliable way either from tokens, frames, vocabulary or embed_weights, and to which new_weights can be reshaped.\n",
    "\n",
    "Explanation for Embedding Layer: https://mxnet.apache.org/versions/1.6/api/r/docs/api/mx.symbol.Embedding.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embed_weight is initialized with shape(vocab, output_dim) in sockeye, that is why it normally works with F.Embeddings. In this case, the shape of embed_weights is going to change constantly.\n",
    "\n",
    "I cannot read out the shape of new_weights directly in MX_net, but I seem to be able to call a method named shape_array, which returns the shape of new_weights as array. I then can multiply the first and second index to get a reliable input_dim and configuration for a 2d array F.Embedding can read. One of the big questions is if it makes sense to pad the new_weights array until it is as long as the vocabulary.\n",
    "\n",
    "mx.symbol.reshape provides an easy solution for the reshaping problem: new_weights.reshape(-3,output_dim) should have the desired effect, since -3 says that \"the product of two consecutive dimensions of the input shape\" should be used as output shape (source: https://mxnet.apache.org/versions/1.6/api/r/docs/api/mx.symbol.Reshape.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It makes sense to pad the weight array up to (vocab_size, num_embeds), since that might be a format sockeye expects to work with later.\n",
    "\n",
    "Let's assume the length of the vocab is 70. Therefore, the shape of the new weight array should be (70,2), but we currently have the shape (10,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[ 0.          1.        ]\n",
      " [ 0.9092974  -0.41614684]\n",
      " [-0.7568025  -0.6536436 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.84147096  0.5403023 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.84147096  0.5403023 ]\n",
      " [ 0.14112    -0.9899925 ]\n",
      " [-0.7568025  -0.6536436 ]\n",
      " [ 0.          1.        ]]\n",
      "<NDArray 10x2 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "new_weights = new_weights.reshape(len(weights),2)\n",
    "print(new_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int64'>\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "shapes = new_weights.shape_array() #shape_array is also available in mx.symbol\n",
    "\n",
    "expected_length = mx.nd.array([70], dtype='int64')\n",
    "\n",
    "actual_length = shapes.slice(begin=0,end=1)\n",
    "\n",
    "print(actual_length.dtype)\n",
    "print(expected_length.dtype)\n",
    "\n",
    "#shape and dtype of actual and expected_length need to be the same, or subtracting one array from the \n",
    "#other doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[60]\n",
      "<NDArray 1 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "needed_length = expected_length - actual_length\n",
    "\n",
    "print(needed_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[60  2]\n",
      "<NDArray 2 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "pad_shape = mx.ndarray.concat(needed_length, mx.nd.array([2], dtype='int64'), dim=0)\n",
    "\n",
    "print(pad_shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 2)\n"
     ]
    }
   ],
   "source": [
    "padding = mx.ndarray.zeros((60,2)) #theoretically, this works with the needed_length array in symbolic programming\n",
    "#it doesn't work with needed_lenght and ndarrays in imperative programming, that's why I inserted the tuple here.\n",
    "print(padding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 2)\n"
     ]
    }
   ],
   "source": [
    "new_weights_2 = mx.ndarray.concat(new_weights, padding, dim = 0)\n",
    "print(new_weights_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last proposed solution doesn't work, because symbol.zeros also needs a tuple as input, and there is no easy way to get an int value from needed_length into that tuple.\n",
    "\n",
    "Next idea: create an array with zeros with shape = (vocab_size, num_embeds) (a.k.a the target shape), concat it to the weights array, and then slice the weight array such that the shape of the weight array is (vocab_size, num_embeds). That should work, because vocab_size and num_embeds are both integers that can be called through config, not symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2)\n"
     ]
    }
   ],
   "source": [
    "print(new_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 2)\n"
     ]
    }
   ],
   "source": [
    "padding = mx.ndarray.zeros((70,2))\n",
    "\n",
    "print(padding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 2)\n"
     ]
    }
   ],
   "source": [
    "new_weights_3 = mx.ndarray.concat(new_weights, padding, dim = 0)\n",
    "\n",
    "new_weights_3 = mx.ndarray.slice(new_weights_3, begin = (0,0), end=(70,2))\n",
    "print(new_weights_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[ 0.          1.        ]\n",
      " [ 0.9092974  -0.41614684]\n",
      " [-0.7568025  -0.6536436 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.84147096  0.5403023 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.84147096  0.5403023 ]\n",
      " [ 0.14112    -0.9899925 ]\n",
      " [-0.7568025  -0.6536436 ]\n",
      " [ 0.          1.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]\n",
      " [ 0.          0.        ]]\n",
      "<NDArray 70x2 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "print(new_weights_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that finally works with mxnet's symbolic programming API."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
